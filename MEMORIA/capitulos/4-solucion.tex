

\chapter{Descripción de la Solución}
\label{sec-4}

\label{cap:solucion}

  La solución propuesta consistió en generar un resumen utilizando
  documentos representados apropiadamente con la información de medios
  sociales que los mencionan. La relevancia de estos documentos
  también se obtuvo con la información social más otros indicadores de
  la solución parcial.

  Para esto, se asume que existe una fuente de eventos, de esta forma,
  el enfoque de la solución radica principalmente en la selección y 
  ordenamiento de los elementos, o generación de resúmenes, y no en 
  la identificación de eventos en medios sociales.

  La Figura \ref{fig:overview} muestra de manera general el modelo
  propuesto. El modelo considera varias etapas: obtención de eventos,
  enriquecimiento desde medios sociales para la generación de
  documentos, identificación de subtópicos y la selección de los $k$
  más relevantes.

\begin{enumerate}
\item La obtención de eventos consiste en la recolección de metadatos
     sobre eventos del mundo real, para esto se asume una fuente
     existente, siendo el problema de identificación de eventos fuera
     del alcance de este trabajo.
\item Con los metadatos recolectados, se realizan búsquedas en medios
     sociales para la obtención de mensajes a partir de estos
     metadatos. Con estos mensajes, se generan documentos utilizando la
     información que contienen, mediante una representación adecuada.
\item Se identifican los subtópicos de cada evento a partir de los
     documentos, generando clusters de documentos.
\item Finalmente, se utiliza la información social de los documentos
     (obtenida a partir de los medios sociales) para generar una medida
     de relevancia, y poder seleccionar los $k$ documentos más
     relevantes.
\end{enumerate}

  \begin{figure}[h!b]
  \centering
  \includegraphics[width=11cm]{./dia/model2.ps}
  \caption[Vista general de la solución.]
   {Vista general de la solución\label{fig:overview}. En ésta se
  pueden apreciar las etapas de la metodología: (1) obtención de los
  eventos, (2) generación de los documentos a partir de mensajes
  obtenidos de medios sociales, (3) identificación de subtópicos de
  cada evento, y (4) selección de los $k$ más relevantes.}
  \end{figure}

  Se utilizaron las API de Google News y de Last.fm para la
  obtención de eventos: noticias y conciertos, respectivamente. Para
  el enriquecimiento de los eventos se utilizó la información social
  que provee la red social Twitter y su API de búsqueda de
  \emph{tweets}. De la misma forma, se consideraron los metadatos de los
  mismos mensajes para medir la relevancia de los documentos generados.

  Un documento es identificado por la URL que lo ubica en la Web. El
  contenido no es más que la concatenación de los tweets que
  mencionan al documento. Se realizó una limpieza y preprocesamiento
  de los datos, quitando las \emph{stopwords} y realizando \emph{stemming}
  sobre el contenido en texto. Luego, se aplicó \emph{tf-idf} sobre los
  documentos, representándolos como vectores en el \emph{space vector model}. 
  Para identificar los subtópicos o clusters de un evento se utilizó el
  algoritmo de clustering $k$-means sobre los vectores.

  Para el ranking de los documentos se decidió usar una ponderación
  simple sobre una serie de indicadores que dependen de los tweets y
  de las URLs de cada evento.

  Entre las herramientas utilizadas, se usó lenguaje de
  programación Python, varias librerías para el manejo de datos
  (tales como \texttt{nltk}, \texttt{scipy}, \texttt{scikit-learn}, por nombrar las más
  importantes), el sistema de almacenamiento Redis, entre otras
  herramientas que son mencionadas en la descripción detallada de la
  solución.

  En la Sección \ref{descdet} se describe el modelo utilizado para la
  implementación, con una especificación detallada de la solución. En la
  Sección \ref{impl} se describe la metodología de desarrollo y la
  implementación práctica realizada para representar el modelo
  formal, la cual considera la obtención de datos dentro del
  proceso. Luego se comentan los problemas técnicos que fueron
  enfrentados para terminar en la Sección \ref{casosest}, donde se discuten
  un par de casos de estudio sobre los resultados obtenidos.


\section{Descripción detallada}
\label{sec-4.1}

\label{descdet}


   Para enfrentar el problema descrito se decidió utilizar una
   representación apropiada de los documentos que permita abstraerse
   de su contenido, utilizando la información social asociada a
   éstos. Se decidió que el problema de identificación de eventos está
   fuera del alcance de este trabajo, por lo cual, se asume que los
   eventos son dados como input a la solución diseñada. A partir de un
   evento determinado, se identifican los  subtópicos del evento
   utilizando los documentos, y luego, para cada
   subtópico se determinan los documentos más relevantes utilizando
   esta información social.

   Para esto, fue necesario contar con dos \emph{fuentes de datos}: una
   fuente de eventos y otra de \emph{contenido social}, en la forma de
   mensajes y actualizaciones de estado.

   Se asumió que estas fuentes satisfacen los siguientes
   requerimientos:

\begin{itemize}
\item La fuente de eventos debe entregar una lista de eventos
     rápidamente, la cual debe contener los siguientes datos para
     cada entrada:

\begin{itemize}
\item Un título del evento y \emph{términos asociados}. Los términos
       asociados son breves frases o palabras que describan al
       evento, como por ejemplo, tags o etiquetas.
\item Como datos opcionales: breve descripción del evento, fecha de
       inicio y término, ubicación y direcciones Web.
\end{itemize}

\item La o las fuentes de contenido social deben entregar una lista de
     mensajes, con algunos metadatos tales como la fecha de creación,
     si el mensaje fue compartido, etc. Además, algunos datos sobre el
     autor del mensaje, como la cantidad de conexiones en la red, y
     en general, datos que permitan comparar dos autores.
\end{itemize}
   Utilizando estas dos fuentes, el siguiente paso luego de obtener
   una lista de eventos fue enriquecerlos utilizando las fuentes
   sociales, generando documentos del tipo
   $d = (s_1, s_2, \ldots, s_m)$, donde  $s_i$, $i \in [1..m]$
   es un mensaje de alguna fuente social, con los
   metadatos asociados. El documento es identificado por la URI de
   algún documento en la Web, de forma que todos los mensajes que
   contengan una URI en particular, corresponderán al mismo documento
   $d$.

   A continuación, utilizando alguna representación adecuada
   (\emph{vector space model}, \emph{bag of words}, etc.), se generaron clusters
   de documentos de un mismo evento, identificando los subtópicos. Con
   ellos fue posible generar un resumen que abarcara todos los
   aspectos del evento, en contraste con seleccionar directamente los
   documentos más relevantes del evento en su conjunto, lo cual puede
   dejar puntos de vista sin ser considerados por su extensión.

   Finalmente se seleccionaron los $k>0$ documentos más representativos de
   cada cluster, utilizando como criterio los metadatos de los
   mensajes de la fuente social. De esta forma, se ordenan los
   documentos dejando como más ``relevantes'' los que más interés atrae
   de los usuarios.

\section{Metodología de desarrollo e implementación}
\label{sec-4.2}

\label{impl}

   La implementación consistió en las siguientes etapas:

\begin{itemize}
\item Obtención del dataset de eventos y documentos.

     Para esto, se utilizaron dos fuentes de eventos: Google News y
     Last.fm para recolectar noticias y conciertos musicales
     (incluidos festivales), respectivamente. Como fuente de datos
     sociales se utilizó la red social Twitter, que dispone de una API
     para realizar búsquedas por \emph{keywords}. Esta etapa comprendió
     la recolección de eventos y de documentos con información social
     asociada a éstos.
\item Generación de clusters para la identificación de subtópicos para
     cada evento.

     Una vez identificados los eventos y los documentos asociados, se
     generaron clusters usando el algoritmo K-means con K-means++ para
     la inicialización. Se impuso un valor de $k=5$ clusters por
     evento. En la sección de casos de estudio se discuten las
     alternativas y la evaluación de algunos clusters del dataset.
\item Extracción de documentos relevantes para cada evento.

     Una vez identificados los subtópicos de cada cluster, se
     extrajeron de éstos los documentos más relevantes, utilizando la
     información social de cada uno de ellos, en conjunto con otros
     indicadores globales del clustering (como que incluyan una URL
     dentro de las más mencionadas dentro del cluster, entre
     otras). Estos documentos corresponden al output o salida del
     sistema.
\end{itemize}
\subsection{Obtención de datos}
\label{sec-4.2.1}

    Se describe a continuación el proceso diseñado para la obtención de
    datos, tanto de eventos como de documentos con sus indicadores
    sociales respectivos.

    Las etapas de generación del dataset fueron las siguientes:

\begin{itemize}
\item Recolección de eventos (noticias y conciertos);
\item Enriquecimiento de los eventos existentes mediante tweets; e
\item Identificación de documentos a partir de los tweets por cada evento.
\end{itemize}
    Se recolectaron datos (eventos y tweets) desde el 19 de noviembre de
    2012 hasta el 30 de noviembre del mismo año, todos los días
    desde la medianoche hasta que el proceso termina exitosamente.

\subsubsection{Recolección de eventos}

Se consideraron dos tipos de eventos para el sistema: noticias y
conciertos musicales. Los conciertos incluyen festivales de varios
artistas.

\begin{itemize}
\item \textbf{Noticias}

  Para obtener las noticias, se utilizó el servicio de Google
  News. Existe una API (en proceso de
  obsolescencia\footnote{\href{http://googlecode.blogspot.com/2011/05/spring-cleaning-for-some-of-our-apis.html}{http://googlecode.blogspot.com/2011/05/spring-cleaning-for-some-of-our-apis.html} },
  pero funcional a la fecha de este trabajo) que permite
  obtener no sólo los titulares y breve descripción de cada noticia,
  sino también un conjunto de entre 4-10 noticias relacionadas de otras
  fuentes. Esto sirvió para alimentar los términos de búsqueda para la
  etapa siguiente. Se guardaron los siguientes datos de una noticia:

\begin{itemize}
\item Título,
\item Descripción,
\item URL de la fuente, y
\item Titulares de las noticias relacionadas.
\end{itemize}

\item \textbf{Conciertos}

  Utilizando el servicio de Last.fm para obtener los conciertos y
  festivales de una ubicación en
  particular\footnote{\href{http://www.lastfm.es/api/show/geo.getEvents}{http://www.lastfm.es/api/show/geo.getEvents} }, se
  obtuvieron los conciertos y festivales de las siguientes
  ubicaciones:

\begin{itemize}
\item Santiago, Chile;
\item Londres, Inglaterra;
\item Glastonbury, Inglaterra;
\item Las Vegas, Nevada, EE.UU.; y
\item Estocolmo, Suecia.
\end{itemize}

\item Título del evento (concierto o festival);
\item Artistas que participan; y
\item Fechas de inicio y término (esta última no siempre está como
    dato).


  Además de otros datos descriptivos, como la ubicación, descripción
  breve, sitio web de la banda o festival, etc.
\end{itemize}
Cada vez que se obtienen los eventos se vuelven a obtener los
conciertos, pero sólo agregando los nuevos. Las noticias siempre son
nuevas, aun así por implementación no se consideraron los repetidos.

\subsubsection{Enriquecimiento de eventos}

Se obtuvieron tweets utilizando el servicio de búsqueda que provee
Twitter en su
API\footnote{\href{https://dev.twitter.com/docs/api/1.1/get/search/tweets}{https://dev.twitter.com/docs/api/1.1/get/search/tweets} }. El
objetivo es enriquecer los eventos con la información social que hay
en la Web sobre éstos.

Para cada uno de los eventos obtenidos en la fase anterior, se
utilizaron los términos de búsqueda asociados a ellos: los titulares
de las noticias relacionadas y los nombres de los artistas para los
eventos noticiosos y musicales, respectivamente.

\begin{itemize}
\item Para las noticias, se hace una búsqueda en Twitter de los titulares
  al mismo tiempo en que se obtienen de Google News, y nuevamente al
  día siguiente, es decir, 2 búsquedas por cada titular de un evento.
  Se quitan las tildes y caracteres no \texttt{ASCII} y las stopwords, para
  evitar problemas con la implementación y no hacer calce de stopwords
  en la búsqueda de Twitter.
\item Para los conciertos y festivales, se utilizaron los nombres de los
  artistas y del evento como términos de búsqueda. De acuerdo a la
  información asociada al evento, se busca por una mayor cantidad de
  días:

\begin{itemize}
\item Se busca desde un día antes de inicio del evento;
\item Si está presente la fecha de término del evento, se busca cada día
    dentro del intervalo ``fecha de inicio'' a ``fecha de término'' hasta
    tres días terminado el evento.
\item Si no está presente la fecha de término (por ejemplo, un concierto
    o un festival de un día), se busca hasta tres días pasada la fecha
    de inicio.
\end{itemize}

\end{itemize}
\subsubsection{Identificación de documentos a partir de tweets}

    Luego de obtener los tweets asociados a cada evento, el siguiente
    paso fue generar los documentos que fueron usados para la
    generación de los resúmenes. Nuevamente, el modelo consistió en que cada
    documento se modeló como un vector de palabras, donde el
    identificador del documento es una URL, y sus componentes
    corresponden al contenido de los tweets que tienen esa URL en el
    texto del mensaje.

    El caso en el que un tweet no tenía ninguna URL en su contenido
    fue abordado de la siguiente forma: la URL asociada es una tal que
    representa al mismo tweet (utilizando el servicio de Twitter), y
    el contenido de ese documento es el mismo tweet, de forma de no
    dejar el tweet sin ser representado.

    Este proceso fue abordado recorriendo todos los eventos del
    dataset, observando todos los tweets asociados a cada evento,
    extrayendo la URL si es que hay alguna y guardando el documento
    con el nuevo tweet. Se marcan los tweets observados para no tener
    que repetir el proceso, ya que es intensivo en conexión a la red.

    Dada la condición breve de los mensajes publicados en la red
    social, muchos de los usuarios y/o servicios que publican mensajes
    con una URL en su interior suelen utilizar \emph{acortadores}
    (o \emph{url shorteners}) para los enlaces, y así no utilizar mucho
    espacio dentro de un
    mensaje. Otra ventaja que ofrecen es que algunos servicios como
    Bit.ly\footnote{\href{http://bit.ly}{http://bit.ly} } dan estadísticas sobre los visitantes a
    estos enlaces (y así saber quiénes vienen de cierta red social u
    otra, por ejemplo). Twitter, a su vez, actualmente también ofrece
    acortamiento de URLs por defecto. Esto suele producir que un enlace
    acortado se resuelva a otro enlace también acortado, por lo que es
    necesario resolver la URL completa para evitar duplicados o
    \emph{pseudo-duplicados} (en el caso en que dos URLs sintácticamente
    distintas apunten al mismo recurso). En la Figura \ref{fig:short}
    se puede apreciar un ejemplo de cómo estos enlaces pueden apuntar
    al mismo recurso, por lo cual hay que resolverlos completamente
    para evitar pseudo-duplicados.

  \begin{figure}[h]
  \centering
  \includegraphics[width=16cm]{./dia/shortlinks.ps}
  \caption[Ejemplo de enlaces acortados.]
   {Ejemplo de enlaces acortados. Los dos primeros se resuelven
  primero a otros enlaces cortos que finalmente se resuelven a un
  nodo terminal (que se resuelve a su misma URL). El tercer link se
  resuelve directamente al nodo terminal.\label{fig:short}}
  \end{figure}

    Por lo anterior, una vez identificada la URL del texto de un
    tweet, se resuelve su URL completa (que puede ya serlo de
    antemano), lo que consume recursos de ancho de banda y
    tiempo.

    Una vez identificada la URL, si existía el documento previamente,
    se añade el tweet a éste, sino se crea un nuevo documento cuyo
    identificador es la URL encontrada:

\begin{verbatim}
 Event: Kamelot
 Event type: Concert
 Document URL: http://www.youtube.com/watch?v=pkiZOTc_tTw&feature=related
 Document content:
 ['#np Kamelot - Can You Remember? :http://t.co/s7MUh7VW',
  'RT @El__Azar: #np Kamelot - Can You Remember? :http://t.co/s7MUh7VW']
\end{verbatim}


\subsection{Identificación de subtópicos}
\label{sec-4.2.2}


    Una vez recolectados tanto los eventos como generados los
    documentos asociados, se procedió a identificar los subtópicos de
    cada evento. Para esto, se utilizó el algoritmo K-means para
    construir clusters a partir de todos los documentos de un solo
    evento.

    Como se mencionó anteriormente, los documentos consisten en
    vectores del tipo $d_{\textrm{URL}}=(t_1,t_2,\ldots,t_m)$, donde
    $t_i$ es el tweet $i$-ésimo que contiene a URL dentro del texto
    del mensaje. Para poder aplicar un algoritmo de clustering, fue
    necesario procesar nuevamente estos documentos para representarlos
    como vectores usando el vector space model. El procedimiento
    consta de dos partes, ``normalizar'' los documentos, limpiando los
    términos que puedan afectar al clustering, y luego aplicar
    $\tfidf$ sobre los documentos normalizados:

\begin{algorithm}[H]
 \KwData{Conjunto de documentos $D_e$}
 \KwResult{Conjunto de strings $D'_e$, }
 $D'_e \leftarrow \emptyset$\;
 \For{documento $d \in D_e$}{
   $d' \leftarrow \varepsilon$\;
   \For{tweet $t \in d$}{
   $t' \leftarrow \texttt{clean}(t)$\;
   $d' \leftarrow \texttt{concat}(d',t')$\;
   }
   $D'_e \leftarrow D'_e \cup \{d'\}$\;
 }
 \caption{Preprocesamiento de documentos}
\end{algorithm}

    Donde $\varepsilon$ es el string vacío, \texttt{concat}$(a,b)$ retorna
    la concatenación de $a$ y $b$, y \texttt{clean} realiza las siguientes
    operaciones sobre el tweet:

\begin{itemize}
\item Remueve las URLs que contenga el texto;
\item Remueve todas las menciones;
\item Quita los caracteres ``\#'', dejando los \emph{hashtags} intactos;
\item Quita las tildes, acentos, stopwords; y
\item Realiza stemming en español o inglés dependiendo del idioma del
      evento dado por los metadatos de éste. Se utilizó el Snowball
      Stemmer\footnote{\href{http://snowball.tartarus.org/}{http://snowball.tartarus.org/} } para esto.
\end{itemize}
    Una vez normalizados los documentos, se convierten a la
    representación como vectores con pesos por cada término:

\begin{algorithm}[H]
\KwData{Conjunto de strings $D'_e$, vocabulario $V$ de palabras de
$D'_e$}
\KwResult{Conjunto de vectores $D''_e$, representados en vector space
model}
$D''_e \leftarrow \emptyset$ \;
\For{documento $d \in D'_e$} {
   $d' \leftarrow \texttt{map}(\tfidf(\cdotp, d, D'_e), \texttt{words}(d))$\;
}
$D''_e \leftarrow D''_e \cup \{d'\}$\;
\caption{Transformación de documentos a vector space model}
\end{algorithm}

    Donde \texttt{map}$(f,l)$ mapea la
    función o procedimiento $f$ a cada elemento de la lista $l$,
    retornando una nueva lista $l'$ en la cual a cada elemento se le
    aplicó $f$ y \texttt{words} retorna una lista con las palabras de
    $d'$. Este procedimiento retorna un conjunto de vectores en
    $\tfidf$, lo que permite entonces aplicar un algoritmo de
    clustering para identificar subtópicos.

    Se utilizó el algoritmo
    K-means\footnote{\href{http://scikit-learn.org/stable/modules/clustering.html}{http://scikit-learn.org/stable/modules/clustering.html} }
    que provee la librería
    \texttt{scikit-learn} para generar los clusters. Al
    aplicarlo sobre el conjunto de vectores, éste retorna una
    \emph{lista de etiquetas} $L$, de largo $n$, la cantidad de documentos
    utilizados. Cada $L_i \in [0..k-1], i \in [1..n]$ indica a cuál
    cluster corresponde el $i$-ésimo documento, lo que permite
    fácilmente filtrar y recuperar los clusters por separado, para
    pasar a la siguiente etapa.


\subsection{Ranking de documentos}
\label{sec-4.2.3}


    Para generar un ranking de documentos, se procedió a obtener toda
    la información relevante de éstos. Se escogió un conjunto de
    indicadores según \cite{Castillo:2011:ICT:1963405.1963500} y las
    conclusiones de \cite{Duan:2010:ESL:1873781.1873815}, en
    las cuales se menciona
    que la \emph{popularidad} de un autor de un tweet, el largo de un tweet
    y si éste contiene o no una URL, son los mejores indicadores para
    medir la relevancia de un tweet, según los experimentos llevados a
    cabo.

    La popularidad o \emph{autoridad} de un usuario en Twitter, se mide,
    como se menciona en el trabajo referenciado, de acuerdo a en
    cuántas listas de otros usuarios está este autor, en vez de
    ponderar por la cantidad de seguidores o amigos en la red social,
    dado que un usuario con muchos seguidores puede tener otras
    explicaciones aparte de ser un usuario ``influyente''; por ejemplo,
    puede ser una cuenta de \emph{spam} o alguna celebridad de farándula.

    Se decidió utilizar una metología simple para asignar un puntaje a
    cada documento, dada la complejidad de entrenar un sistema de
    Learning to Rank, puesto que esto implica asignar puntajes a muchos datos con
    anticipación. Además, dado que se pueden hacer muchos ajustes a los
    pasos previos, una solución muy especializada posiblemente no
    entregaría mejores resultados en comparación.

    Con esto, se decidió asignar un puntaje a cada indicador, el cual se aplica
    al promedio de los indicadores para cada documento, cuando
    corresponde, y luego se suman dando el puntaje para ese
    documento. Con esto es posible generar un orden y entregar los $k$
    primeros, para un parámetro $k$ escogido.

    Los indicadores escogidos se pueden apreciar en la Tabla
    \ref{tbl:indicadores}. En el Código \ref{fig:doc-example} se puede
    apreciar un ejemplo de la información obtenida para un documento.




\begin{table}[htb]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
 Indicador        &  Descripción                                                   &  Puntaje  \\
\hline
\hline
 TWEETS           &  Número de tweets del documento                                &  $0.152$  \\
 RETWEETS         &  Número de retweets de los tweets del documento                &  $0.091$  \\
 TWEET\_LENGTHS   &  Largos de los tweets del documento, en cantidad de palabras   &  $0.091$  \\
 USER\_VERIFIED   &  Número de tweets cuyo autor está verificado por Twitter       &  $0.21$   \\
 USER\_FOLLOWERS  &  Número de usuarios que siguen a cada autor                    &  $0.061$  \\
 USER\_LISTS      &  Número de listas en las cuales están estos autores            &  $0.182$  \\
 USER\_STATUSES   &  Número de tweets que han escrito los autores                  &  $0.061$  \\
 USER\_FRIENDS    &  Número de usuarios que siguen y son seguidos por los autores  &  $0.12$   \\
 USER\_GEO        &  Número de autores cuyos tweets tienen ubicación habilitada    &  $0.03$   \\
\hline
\end{tabular}
\end{center}
\caption{\label{tbl:indicadores}Indicadores sociales utilizados para medir relevancia. Todos los indicadores son sumas entre todos los tweets de un documento.}
\end{table}

\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               bgcolor=bg,
               fontsize=\small,
               tabsize=4]{js}
{
"850a0f7e08e9cf2e080678679857eef9": {
  "domain": "twitter",
  "is_retweet": [0, 0, 0, 0, 0, 0],
  "num_tweets": 6,
  "retweets": ["0", "0", "0", "0", "0", "0"],
  "tweets_lengths": [8, 6, 8, 6, 6, 8],
  "url": "https://api.twitter.com/1/statuses/show.json?id=270299718540738560",
  "user_created_at": [1309224895.0,
                      1285052229.0,
                      1309224895.0,
                      1285052229.0,
                      1285052229.0,
                      1309224895.0],
  "user_followers": ["45", "37", "45", "37", "37", "45"],
  "user_friends": ["2", "25", "2", "25", "25", "2"],
  "user_geo_enabled": [1, 0, 1, 0, 0, 1],
  "user_is_verified": [0, 0, 0, 0, 0, 0],
  "user_lists": ["0", "1", "0", "1", "1", "0"],
  "user_statuses": ["12484", "4756", "12484", "4756", "4756", "12484"]}
}
\end{minted}
\caption{Información de un documento, correspondiente al evento ``Anef
anuncia movilización nacional''. Los campos que corresponden a listas
indican los valores para cada tweet del documento, en este caso, el
documento tiene 6 tweets; por ejemplo, user\_followers[24]=45 indica
la cantidad de seguidores que tiene el autor del tweet en la tercera
posición.}
\label{fig:doc-example}
\end{listing}






\section{API de búsqueda de Twitter}
\label{sec-4.3}

%\subsection{Restricciones de la API de Twitter}
%\label{sec-4.3.1}


   La API de búsqueda de Twitter permite obtener tweets de acuerdo a un
   término de búsqueda. Se utilizó este servicio para enriquecer los
   eventos con información social utilizando como términos de búsqueda
   tanto los títulos de las noticias como los nombres de los artistas
   para las noticias y los conciertos, respectivamente.

   Funciona de la siguiente manera: cada vez que se hace un request a la
   URL dada por el servicio, éste retorna a lo más 100 tweets por página, con un
   máximo de 15 páginas (indicando en el request qué página queremos
   consultar), dando como total hasta 1500 tweets por búsqueda. Existirán
   términos de búsqueda que no presenten ningún resultado  (ya sea por
   estar mal escritos o simplemente que no sean un tópico de discusión), o por
   el contrario, que se generen más tweets que los retornados por la
   búsqueda por cada ventana de tiempo que demore ésta (por ejemplo, un
   \emph{trending topic} o tópico que sea muy mencionado en la red social).

   Existe una limitación de uso de este servicio: sólo es posible hacer
   hasta 180 requests por cada 15 minutos, o 1 request cada 5
   segundos. Además, sólo retorna tweets de hasta 7 días de antigüedad, y
   sus resultados no son necesariamente en tiempo real y su estabilidad
   varía de acuerdo a factores externos. Esto implicó que la etapa de
   enriquecimiento de eventos y generación de documentos haya sido muy
   costosa en tiempo, dado que se pueden obtener a lo más 100 tweets
   cada 5 segundos.

   Los tweets devueltos vienen en formato \texttt{JSON} (\emph{Javascript Simple Object Notation}),
   e incluyen varios metadatos sobre el tweet aparte de los principales,
   como autor, fecha, contenido. Algunos de estos metadatos son:

\begin{itemize}
\item Cantidad de \emph{retweets} hechos hasta la fecha;
\item Si posee alguna URL o \emph{hashtag} en el texto;
\item Si es una \emph{mención} a otro usuario;
\item La ubicación de donde se envió el tweet;
\item etc.
\end{itemize}
  Además, incluye datos sobre el autor, como por ejemplo:

\begin{itemize}
\item Si la cuenta está \emph{verificada};
\item La cantidad de seguidores del usuario;
\item Cantidad de amigos (seguidores que también lo siguen);
\item Cantidad de tweets;
\item Su descripción, y si incluye alguna URL, etc;
\item Ubicación (dada por el mismo usuario);
\item Fecha de creación de la cuenta;
\item etc.
\end{itemize}


\section{Casos de estudio}
\label{sec-4.4}

\label{casosest}

  Fueron analizados 4 eventos, dos noticiosos y dos musicales, en los
  cuales se realizaron distintas actividades:

\begin{itemize}
\item Distribucion de dominios: determinar cuáles son los dominios más
    usuales según los documentos que los apuntan.
\item Determinar número óptimo de clusters: dado que se determinó un
    número fijo de clusters para cada evento, es posible que no sea un
    número adecuado dada la naturaleza de los datos.
\item Analizar contenido de los clusters: se realizó también un análisis
    de los resultados obtenidos.
\end{itemize}
  Los eventos fueron los siguientes:
\begin{itemize}
\item Noticiosos:

\begin{itemize}
\item \texttt{Police arrest suspects in Tel Aviv} (250 documentos)
\item \texttt{Clinton to join Gaza ceasefire effort} (1022 documentos)
\end{itemize}

\item Musicales:

\begin{itemize}
\item \texttt{Sound of Stockholm 2012} (8117 documentos)
\item \texttt{New York Philarmonic Dvorak's New World Symphony} (150
      documentos)
\end{itemize}

\end{itemize}
  Como se puede apreciar, se escogieron eventos con baja y alta
  cantidad de documentos, de forma de poder evaluar el impacto del
  número de documentos en la calidad de los resultados obtenidos.

\subsection{Distribuciones de dominios}
\label{sec-4.4.1}


    A partir de la representación de documentos generada, se determinó
    la distribución de frecuencias de dominios Web, los cuales son los
    identificadores de los documentos. A continuación se presentan
    algunos de los resultados obtenidos:

\begin{figure}[h]
  \centering
  \includegraphics[width=14cm]{./img/telaviv-domain-freqs.png}
  \caption[Dominios evento 1]
   {Distribución de frecuencias de dominios del evento ``Police Arrest
  suspects in Tel Aviv"\label{fig:telaviv-domains}. Las frecuencias son relativas al total de
  documentos correspondientes al evento. Se puede apreciar rápidamente
  que la mayoría de los documentos tienen enlaces a Twitter.}
\end{figure}

\begin{itemize}
\item En la Figura \ref{fig:telaviv-domains} se aprecia una gran
      mayoría de documentos que tienen como URL \texttt{api.twitter.com}, lo
      cual significa que los tweets de esos documentos no presentaron
      ninguna URL en su contenido (dado que esos tweets pasan a
      representar un documento cuyo identificador es una URL que
      identifica al tweet que lo compone).

      En segundo lugar, la URL \texttt{adf.ly} tiene una segunda
      mayoría. \hyperref[sec-4.4.1]{Adf.ly} es un servicio de acortamiento de enlaces, con
      la característica de que el sitio muestra publicidad antes de
      mostrar el enlace a la URL a la cual apunta. Como no es una
      redirección directa, al tratar de resolver este dominio no fue
      posible recuperar destino final. Es posible suponer que los
      destinos de estas direcciones apuntan a más sitios de noticias,
      dadas los dominios que siguen a continuación, como CNN o NY
      Times.
\item De la misma forma, tanto para los eventos ``Clinton'' y
      ``Stockholm'', en las Figuras \ref{fig:clinton-domains} y
      \ref{fig:stockholm-domains}, la distribución de dominios sigue una tónica
      similar: la gran mayoría de documentos corresponden a un tweet
      de sólo texto, sin URL. Es posible que gran parte de los tweets
      hayan correspondido a texto debido a los términos de búsqueda
      que fueron utilizados para recuperarlos, tales como \texttt{clinton},
      \texttt{ceasefire}, \texttt{effort}, o \texttt{stockholm}.
\item Un caso especial ocurre para el evento ``New York'' en la Figura
      \ref{fig:dvorak-domains}. No hay una mayoría de documentos
      apuntando a Twitter: de hecho, la gran mayoría de los documentos
      posee una URL distinta, dada la proporción a la que se
      encuentran los dominios más frecuentes.
\end{itemize}
\begin{figure}[h]
  \centering
  \includegraphics[width=14cm]{./img/clinton-domain-freqs.png}
  \caption[Dominios evento 2]
   {Distribución de frecuencias de dominios del evento ``Clinton to
  join Gaza ceasefire effort"\label{fig:clinton-domains}. Las frecuencias son relativas al total de
  documentos correspondientes al evento. Se puede apreciar rápidamente
  que la mayoría de los documentos tienen enlaces a Twitter.}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=14cm]{./img/stockholm-domain-freqs.png}
  \caption[Dominios evento 3]
   {Distribución de frecuencias de dominios del evento ``Sound of
  Stockholm 2012"\label{fig:stockholm-domains}. Las frecuencias son relativas al total de
  documentos correspondientes al evento. En este caso se quitó del
  gráfico lo que corresponde a Twitter, dejando los datos
  restantes. Se puede apreciar que los siguientes dominios representan
  no más del 10\% del total.}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=14cm]{./img/dvorak-domain-freqs.png}
  \caption[Dominios evento 4]
   {Distribución de frecuencias de dominios del evento ``New York
  Philarmonic Dvorak's New World Symphony"\label{fig:dvorak-domains}. Las frecuencias son relativas al total de
  documentos correspondientes al evento.}
\end{figure}

\subsection{Determinación del número de clusters}
\label{sec-4.4.2}


Para determinar un número adecuado de clusters para cada evento se
utilizaron métricas de evaluación internas, dado que no se contó con
las clases reales de los datos obtenidos. Para esto, se utilizó el
software Cluto\footnote{\href{http://glaros.dtc.umn.edu/gkhome/views/cluto}{http://glaros.dtc.umn.edu/gkhome/views/cluto} }, el
cual ofrece varios algoritmos de clustering con medidas de evaluación
tanto internas (similitud intra-cluster y inter-cluster) como externas
(pureza y entropía).

La metodología utilizada para determinar el número de clusters fue la
siguiente:

\begin{itemize}
\item Calcular una solución de clustering particional usando
  $k \in \{2,\ldots,30\}$ clusters como parámetro.
\item Para cada solución obtenida, documentar la similitud intra-cluster
  promedio y inter-cluster promedio.
\item Determinar experimentalmente la solución con mayor similitud
  intra-cluster y menor similitud inter-cluster, calculando el radio
  entre estas dos medidas.
\end{itemize}
\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{./img/telaviv-clusters-radio.png}
  \caption[Radios de similitud para evento 1]
   { Radio ISim/ESim del evento ``Tel Aviv". El eje de las abscisas corresponde a la cantidad de clusters que se generan para la matriz de $\tfidf$, mientras que el eje de las ordenadas corresponde al radio ISim/ESim de la solución obtenida los clusterings. Se aprecia un máximo del radio cuando el número de clusters es 9, lo que muestra que es conveniente utilizar 9 clusters para este evento. \label{fig:telaviv-radio} }
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{./img/clinton-clusters-radio.png}
  \caption[Radios de similitud para evento 2]
   { Radio ISim/ESim del evento ``Clinton". El radio, en este caso, aumenta a medida que se aumenta el número de clusters, siendo el máximo en 27 clusters, para esta experimentación. Se podría apreciar un número mayor si se prueba con más clusters, sin embargo, no pareció que hacerlo influyera en la calidad efectiva de la solución. \label{fig:clinton-radio} }
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=12cm]{./img/stockholm-clusters-radio.png}
  \caption[Radios de similitud para evento 3]
   { Radio ISim/ESim del evento ``Stockholm". En este caso, se aprecia un máximo local con 11 clusters.\label{fig:stockholm-radio}}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=12cm]{./img/dvorak-clusters-radio.png}
  \caption[Radios de similitud para evento 4]
   { Radio ISim/ESim del evento ``New York". Se aprecian dos máximos, con 25 y 28 clusters, respectivamente. Al ser máximos locales, es posible que a mayor número de clusters las soluciones puedan tener mejores medidas de similitud. \label{fig:dvorak-radio} }
\end{figure}

Con esto, se puede determinar experimentalmente un número de clusters
para cada evento, y analizar los resultados obtenidos. En las Figuras \ref{fig:telaviv-radio}, \ref{fig:clinton-radio}, \ref{fig:stockholm-radio}, y \ref{fig:dvorak-radio} se pueden apreciar los resultados obtenidos en la determinación del número de clusters.

\subsection{Análisis de resúmenes}
\label{sec-4.4.3}


    Para analizar los resultados obtenidos, se generaron nuevamente
    clusterings utilizando el número estimado en la sección anterior, de
    forma de determinar una solución de mejor calidad. Una vez generados 
    los clusterings, se procedió a hacer un análisis
    caso a caso de los resultados obtenidos.

    Por ejemplo, para el evento ``Tel Aviv'', se determinó como $9$ el
    número óptimo de clusters, dando como resultado una solución de
    clustering que particionaba los tweets de tal forma que cada
    cluster contenía principalmente sólo tweets de cierto tipo. A continuación 
    se muestra el tweet más frecuente por cluster, o bien una descripción de los tweets
    del cluster, al no haber un tweet más repetido:

\begin{enumerate}
\item \texttt{Previous bomb attacks in Tel Aviv...}
\item \texttt{RT @BreakingNews: Israel's army spokesman says Israeli Arab        arrested for Wednesday's bus bombing in Tel Aviv}
\item Este cluster contiene tweets de distintos temas, tanto de Tel Aviv como
       otros relacionados a Israel, Egipto o Estados Unidos, sin haber ninguno repetido en particular.
\item \texttt{RT @chaimlevinson: \#breakingnews : after massive  police hunt,        2  suspects in the tel aviv bus bombing arrested in 443 road}
\item \texttt{Police Arrest Suspects in Tel Aviv Bus Blast, Including        Israeli Citizen:}
\item \texttt{Israel arrests suspects in Tel Aviv bus bombing: Israeli}
       \texttt{authorities arrested an Israeli Arab on suspicion of planting a}
       \texttt{bomb in a Te...}
\item \texttt{Arrest announced in Tel Aviv bus bombing: An arrest has been}
       \texttt{made in Wednesdaybombing in Tel Aviv of a bus, a...}
\item \texttt{RT @panosharitos: Tel Aviv police chasing after two suspects}
       \texttt{(one arrested), say this was not a suicide bombing; 3 of the}
       \texttt{casualties are ...}
\item \texttt{Shin Bet, police arrest suspects in Tel Aviv bus bombing}
       \texttt{http://t.co/hJzLAOnD}
\end{enumerate}
    Los mensajes expuestos son los más frecuentes dentro de su
    cluster, a excepción del cluster n°2, que contenía tweets con
    distintos temas.

    Los resultados del ranking sobre cada cluster entrega
    efectivamente los tweets más ``populares'' dentro de los indicadores
    escogidos (número de retweets, autoridad de la cuenta, etc.). En
    la Figura \ref{fig:bn} se puede apreciar el documento con más
    puntaje obtenido por el ranking. Su alto puntaje se debió
    principalmente a la cantidad de retweets y a que el autor es una
    cuenta verificada.

\begin{figure}    
  \centering
  \includegraphics[width=14cm]{./img/breakingnews.png}
  \caption[Documento con alto puntaje entre los resultados obtenidos]
   { Documento (tweet) con más relevancia dentro del evento ``Tel Aviv". Su relevancia dentro de los resultados se debe principalmente a que el autor posee una cuenta verificada en Twitter, además del número de retweets. \label{fig:bn} }
\end{figure}

    Por otra parte, al analizar los resultados del evento
    ``Stockholm'', que tiene cerca de ocho mil documentos, se notó que
    gran parte de ellos corresponden a tweets sin relación con el tema,
    o bien tweets de contenido personal que no tenían ninguna
    incidencia. Estos tweets alcanzaron alta relevancia debido a altos
    valores en sus indicadores: autoridad de usuarios, cantidad de followers 
    y en ocasiones cantidad de retweets. Esto indica que la forma de
    realizar ranking puede ser mejorada en otros aspectos,
    considerando el contenido del tweet o verificando la validez del documento.

\begin{figure}[h!]
  \centering
  \includegraphics[width=11cm]{./img/dvorak.png}
  \includegraphics[width=11cm]{./img/dvorak2.png}
  \caption[Imagen y documento con altos puntajes entre los resultados obtenidos]
   { Documentos con alta relevancia dentro del evento
  ``New York". El primero corresponde a una imagen en Instagram evaluada con alto puntaje, y el segundo a un tweet de un medio de noticias hablando sobre el evento. \label{fig:dvorak} }
\end{figure}

    Para el evento ``New York'', el cual consiste en un
    concierto musical de la Filarmónica de Nueva York, a pesar de la
    poca cantidad de documentos (250), los resultados fueron
    muy representativos e incluso ricos en contenido multimedia. En la
    Figura\footnote{Fuente \href{http://instagram.com/p/SF8w-3voOF/}{http://instagram.com/p/SF8w-3voOF/} }
    \ref{fig:dvorak}, al final de este capítulo, se puede apreciar uno de los resultados; 
    además de este se incluyen artículos de prensa, vídeos de YouTube,
    grabaciones en servicios de sonido o música como Soundcloud,
    Spotify o Shazam.

    Finalmente, el evento ``Clinton'' obtuvo buenos resultados, en su
    mayoría tweets sin URL, que discuten nuevamente el tema de
    Gaza. Sin embargo, los medios de prensa mencionados en las URLs
    consideran contenido multimedia (imágenes y vídeos), sin embargo,
    se consideró esto anecdótico. La característica de este evento es
    su alto contenido textual en la forma de consignas respecto al
    tópico que discuten.